{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My approach - Network Features Only\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.53      0.54       400\n",
      "          2       0.24      0.24      0.24       400\n",
      "          3       0.22      0.21      0.22       400\n",
      "          4       0.21      0.21      0.21       400\n",
      "          5       0.24      0.27      0.25       400\n",
      "          6       0.27      0.27      0.27       400\n",
      "          7       0.37      0.35      0.36       400\n",
      "\n",
      "avg / total       0.30      0.30      0.30      2800\n",
      "\n",
      "Accuracy: 0.2975\n",
      "MSE: 3.6075\n",
      "\n",
      "\n",
      "KNN\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.61      0.60       400\n",
      "          2       0.32      0.26      0.28       400\n",
      "          3       0.18      0.13      0.15       400\n",
      "          4       0.24      0.17      0.20       400\n",
      "          5       0.23      0.31      0.26       400\n",
      "          6       0.24      0.23      0.23       400\n",
      "          7       0.30      0.41      0.35       400\n",
      "\n",
      "avg / total       0.30      0.30      0.30      2800\n",
      "\n",
      "Accuracy: 0.3032142857142857\n",
      "MSE: 3.956785714285714\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.86      0.61       400\n",
      "          2       0.21      0.19      0.20       400\n",
      "          3       0.27      0.10      0.14       400\n",
      "          4       0.21      0.20      0.20       400\n",
      "          5       0.28      0.24      0.26       400\n",
      "          6       0.30      0.28      0.29       400\n",
      "          7       0.38      0.47      0.42       400\n",
      "\n",
      "avg / total       0.30      0.33      0.30      2800\n",
      "\n",
      "Accuracy: 0.33214285714285713\n",
      "MSE: 3.5828571428571427\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.23      0.87      0.37       400\n",
      "          2       0.11      0.20      0.14       400\n",
      "          3       0.18      0.12      0.15       400\n",
      "          4       0.23      0.03      0.05       400\n",
      "          5       0.33      0.00      0.00       400\n",
      "          6       0.12      0.01      0.01       400\n",
      "          7       0.32      0.15      0.21       400\n",
      "\n",
      "avg / total       0.22      0.20      0.13      2800\n",
      "\n",
      "Accuracy: 0.1982142857142857\n",
      "MSE: 9.055714285714286\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.71      0.66       400\n",
      "          2       0.31      0.30      0.30       400\n",
      "          3       0.31      0.23      0.26       400\n",
      "          4       0.30      0.28      0.29       400\n",
      "          5       0.32      0.27      0.29       400\n",
      "          6       0.32      0.35      0.34       400\n",
      "          7       0.37      0.47      0.42       400\n",
      "\n",
      "avg / total       0.36      0.37      0.37      2800\n",
      "\n",
      "Accuracy: 0.3732142857142857\n",
      "MSE: 2.7903571428571428\n",
      "\n",
      "\n",
      "Support Vector Classifier\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.89      0.58       400\n",
      "          2       0.20      0.15      0.17       400\n",
      "          3       0.34      0.05      0.08       400\n",
      "          4       0.20      0.12      0.15       400\n",
      "          5       0.28      0.18      0.22       400\n",
      "          6       0.29      0.33      0.31       400\n",
      "          7       0.37      0.59      0.45       400\n",
      "\n",
      "avg / total       0.30      0.33      0.28      2800\n",
      "\n",
      "Accuracy: 0.3314285714285714\n",
      "MSE: 3.8460714285714284\n",
      "\n",
      "\n",
      "XGBoost\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.65      0.61       400\n",
      "          2       0.28      0.24      0.26       400\n",
      "          3       0.33      0.28      0.30       400\n",
      "          4       0.27      0.25      0.26       400\n",
      "          5       0.28      0.28      0.28       400\n",
      "          6       0.34      0.35      0.35       400\n",
      "          7       0.36      0.42      0.39       400\n",
      "\n",
      "avg / total       0.35      0.35      0.35      2800\n",
      "\n",
      "Accuracy: 0.35464285714285715\n",
      "MSE: 2.9685714285714284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "import csv\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "# Import classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Change it with the name of your dataset\n",
    "filename = 'MHDataset.csv'\n",
    "\n",
    "# Extract columns names (fieldnames)\n",
    "with open(filename, 'r') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = reader.fieldnames\n",
    "\n",
    "# Remove last column (qualityClass)\n",
    "fieldnames.pop()\n",
    "\n",
    "# IMPORT DATASET\n",
    "data = pd.read_csv(open(filename))\n",
    "\n",
    "# My approach\n",
    "print('My approach - Network Features Only')\n",
    "\n",
    "# Feature list\n",
    "features_cols = [\"pageRank\", \"indegree\", \"outdegree\", \"assortativity_inin\", \"assortativity_inout\", \"assortativity_outin\", \"assortativity_outout\", \"localClusteringCoefficient\", \"reciprocity\", \"linkCount\", \"translationCount\" ]\n",
    "\n",
    "# Select only the columns corresponding to the features in the list\n",
    "X = data[features_cols]\n",
    "\n",
    "X.sample(frac=1)\n",
    "\n",
    "# Select qualityClass as the response (y)\n",
    "y = data.qualityClass\n",
    "\n",
    "# Select only the columns corresponding to the features in the list\n",
    "X = data[features_cols]\n",
    "\n",
    "X.sample(frac=1)\n",
    "\n",
    "# Select qualityClass as the response (y)\n",
    "y = data.qualityClass\n",
    "\n",
    "print('\\n')\n",
    "print('Decision Tree')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with decision tree PREDICTIONS\n",
    "clf = DecisionTreeClassifier(random_state=8)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('KNN')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with knn PREDICTIONS\n",
    "clf = KNeighborsClassifier(n_jobs=7, n_neighbors=49) # NORMAL\n",
    "# clf = KNeighborsClassifier(n_jobs=7, n_neighbors=25) # PARALLEL\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Logistic Regression')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with logistic regression PREDICTIONS\n",
    "clf = LogisticRegression(n_jobs=7)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Naive Bayes')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with naive bayes PREDICTIONS\n",
    "clf = GaussianNB()\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Random Forest')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with random forst PREDICTIONS\n",
    "clf = RandomForestClassifier(n_jobs=7, n_estimators=200, random_state=5, class_weight='auto')\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Support Vector Classifier')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with support vector classifier PREDICTIONS\n",
    "clf = LinearSVC(dual=False)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "print('\\n')\n",
    "print('XGBoost')\n",
    "print('\\n')\n",
    "# fit model no training data\n",
    "model = XGBClassifier(max_depth=3, n_estimators=1000, n_jobs=7)\n",
    "\n",
    "# 10-fold cross-validation with decision tree PREDICTIONS\n",
    "y_pred = cross_val_predict(model, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred) ))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "import csv\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Change it with the name of your dataset\n",
    "filename = 'MHDataset.csv'\n",
    "\n",
    "# Extract columns names (fieldnames)\n",
    "with open(filename, 'r') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = reader.fieldnames\n",
    "\n",
    "# Remove last column (qualityClass)\n",
    "fieldnames.pop()\n",
    "\n",
    "# IMPORT DATASET\n",
    "data = pd.read_csv(open(filename))\n",
    "\n",
    "# My approach\n",
    "print('My approach - Review Features Only')\n",
    "\n",
    "# Feature list\n",
    "features_cols = [ \"age\", \"agePerReview\", \"reviewPerDay\", \"reviewsPerUser\", \"reviewsPerUserStdDev\", \"discussionCount\", \"reviewCount\", \"registeredReviewCount\", \"anonymouseReviewCount\", \"registeredReviewRate\", \"anonymouseReviewRate\", \"registeredAnonymouseReviewRatio\", \"userCount\", \"occasionalUserCount\", \"occasionalUserRate\", \"registeredUserCount\", \"anonymouseUserCount\", \"registerdAnonymouseUserRatio\", \"registeredUserRate\", \"anonymouseUserRate\", \"revertCount\", \"revertReviewRatio\", \"diversity\", \"modifiedLinesRate\", \"mostActiveUsersReviewCount\", \"mostActiveUsersReviewRate\", \"occasionalUsersReviewCount\", \"occasionalUsersReviewRate\", \"lastThreeMonthsReviewCount\", \"lastThreeMonthsReviewRate\" ]\n",
    "\n",
    "# Select only the columns corresponding to the features in the list\n",
    "X = data[features_cols]\n",
    "\n",
    "X.sample(frac=1)\n",
    "\n",
    "# Select qualityClass as the response (y)\n",
    "y = data.qualityClass\n",
    "\n",
    "# Select only the columns corresponding to the features in the list\n",
    "X = data[features_cols]\n",
    "\n",
    "X.sample(frac=1)\n",
    "\n",
    "# Select qualityClass as the response (y)\n",
    "y = data.qualityClass\n",
    "\n",
    "print('\\n')\n",
    "print('Decision Tree')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with decision tree PREDICTIONS\n",
    "clf = DecisionTreeClassifier(random_state=8)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('KNN')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with knn PREDICTIONS\n",
    "clf = KNeighborsClassifier(n_jobs=7, n_neighbors=49) # NORMAL\n",
    "# clf = KNeighborsClassifier(n_jobs=7, n_neighbors=25) # PARALLEL\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Logistic Regression')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with logistic regression PREDICTIONS\n",
    "clf = LogisticRegression(n_jobs=7)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Naive Bayes')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with naive bayes PREDICTIONS\n",
    "clf = GaussianNB()\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Random Forest')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with random forst PREDICTIONS\n",
    "clf = RandomForestClassifier(n_jobs=7, n_estimators=200, random_state=5, class_weight='auto')\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Support Vector Classifier')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with support vector classifier PREDICTIONS\n",
    "clf = LinearSVC(dual=False)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "print('\\n')\n",
    "print('XGBoost')\n",
    "print('\\n')\n",
    "# fit model no training data\n",
    "model = XGBClassifier(max_depth=3, n_estimators=1000, n_jobs=7)\n",
    "\n",
    "# 10-fold cross-validation with decision tree PREDICTIONS\n",
    "y_pred = cross_val_predict(model, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred) ))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "import csv\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Change it with the name of your dataset\n",
    "filename = 'MHDataset.csv'\n",
    "\n",
    "# Extract columns names (fieldnames)\n",
    "with open(filename, 'r') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = reader.fieldnames\n",
    "\n",
    "# Remove last column (qualityClass)\n",
    "fieldnames.pop()\n",
    "\n",
    "# IMPORT DATASET\n",
    "data = pd.read_csv(open(filename))\n",
    "\n",
    "# My approach\n",
    "print('My approach - Text Features Only')\n",
    "\n",
    "# Feature list\n",
    "features_cols = [ \"characterCount\", \"wordCount\", \"syllableCount\", \"sentenceCount\", \"sectionCount\", \"subsectionCount\", \"paragraphCount\", \"meanSectionSize\", \"meanParagraphSize\", \"largestSectionSize\", \"shortestSectionSize\", \"largestShortestSectionRatio\", \"sectionSizeStandardDeviation\", \"meanOfSubsectionsPerSection\", \"abstractSize\", \"abstractSizeArtcileLengthRatio\", \"citationCount\", \"citationCountPerTextLength\", \"citationCountPerSection\", \"externalLinksCount\", \"externalLinksPerTextLength\", \"externalLinksPerSection\", \"imageCount\", \"imagePerTextLength\", \"imagePerSection\", \"meanSentenceSize\", \"largestSentenceSize\", \"shortestSentenceSize\", \"largeSentenceRate\", \"shortSentenceRate\", \"questionCount\", \"questionRatio\", \"exclamationCount\", \"exclamationRatio\", \"toBeVerbCount\", \"toBeVerbRatio\", \"toBeVerbPerSentence\", \"toBeVerbRate\", \"modalAuxiliaryVerbCount\", \"modalAuxiliaryVerbsRatio\", \"modalAuxiliaryVerbsPerSentence\", \"modalAuxiliaryVerbsRate\", \"passiveVoiceCount\", \"passiveVoiceRatio\", \"passiveVoicePerSentence\", \"passiveVoiceRate\", \"numberOfSentencesThatStartWithACoordinatingConjunction\", \"numberOfSentencesThatStartWithADeterminer\", \"numberOfSentencesThatStartWithASubordinatingPrepositionOrConjunction\", \"numberOfSentencesThatStartWithAnAdjective\", \"numberOfSentencesThatStartWithANoun\", \"numberOfSentencesThatStartWithAPronoun\", \"numberOfSentencesThatStartWithAnAdverb\", \"numberOfSentencesThatStartWithAnArticle\", \"numberOfSentencesThatStartWithACoordinatingConjunctionRatio\", \"numberOfSentencesThatStartWithADeterminerRatio\", \"numberOfSentencesThatStartWithASubordinatingPrepositionOrConjunctionRatio\", \"numberOfSentencesThatStartWithAnAdjectiveRatio\", \"numberOfSentencesThatStartWithANounRatio\", \"numberOfSentencesThatStartWithAPronounRatio\", \"numberOfSentencesThatStartWithAnAdverbRatio\", \"numberOfSentencesThatStartWithAnArticleRatio\", \"automatedReadabilityIndex\", \"colemanLiauIndex\", \"fleshReadingEase\", \"fleschKincaidGradeLevel\", \"gunningFogIndex\", \"lasbarhetsIndex\", \"smogGrading\", \"daleChallReadabilityFormula\", \"differentWordCount\", \"differentWordsPerSentence\", \"differentWordsRate\", \"nounCount\", \"nounsPerSentence\", \"nounsRate\", \"differentNounCount\", \"differentNounsPerSentence\", \"differentNounsRate\", \"differentNounsDifferentWordsRatio\", \"verbCount\", \"verbsPerSentence\", \"verbsRate\", \"differentVerbCount\", \"differentVerbsPerSentence\", \"differentVerbsRate\", \"differentVerbsDifferentWordsRatio\", \"pronounCount\", \"pronounsPerSentence\", \"pronounsRate\", \"differentPronounCount\", \"differentPronounsPerSentence\", \"differentPronounsRate\", \"differentPronounsDifferentWordsRatio\", \"adjectiveCount\", \"adjectivesPerSentence\", \"adjectivesRate\", \"differentAdjectiveCount\", \"differentAdjectivesPerSentence\", \"differentAdjectivesRate\", \"differentAdjectivesDifferentWordsRatio\", \"adverbCount\", \"adverbsPerSentence\", \"adverbsRate\", \"differentAdverbCount\", \"differentAdverbsPerSentence\", \"differentAdverbsRate\", \"differentAdverbsDifferentWordsRatio\", \"coordinatingConjunctionCount\", \"coordinatingConjunctionsPerSentence\", \"coordinatingConjunctionsRate\", \"differentCoordinatingConjunctionCount\", \"differentCoordinatingConjunctionsPerSentence\", \"differentCoordinatingConjunctionsRate\", \"differentCoordinatingConjunctionsDifferentWordsRatio\", \"subordinatingPrepositionAndConjunctionCount\", \"subordinatingPrepositionsAndConjunctionsPerSentence\", \"subordinatingPrepositionsAndConjunctionsRate\", \"differentSubordinatingPrepositionAndConjunctionCount\", \"differentSubordinatingPrepositionsAndConjunctionsPerSentence\", \"differentSubordinatingPrepositionsAndConjunctionsRate\", \"differentSubordinatingPrepositionsAndConjunctionsDifferentWordsRatio\", \"syllablesPerWord\", \"charactersPerWord\", \"NNP,NNP,NNP\", \"VBD,DT,JJ\", \"IN,DT,NNP\", \"NNP,IN,DT\", \"DT,NNP,NNP\", \"JJ,NN,IN\", \"NN,IN,DT\", \"IN,DT,NN\", \"NN,IN,NNP\", \"IN,NNP,NNP\", \"NNP,VBD,DT\", \"VBD,DT,NN\", \"DT,NN,IN\", \"VBD,VBN,IN\", \"NNP,NNP,VBD\", \"IN,NN,IN\", \"NNP,NNP,IN\", \"NNP,IN,NNP\", \"VBD,IN,DT\", \"IN,DT,JJ\", \"JJ,NNS,IN\", \"DT,JJ,NN\", \"IN,DT,NNS\", \"IN,CD,NNP\", \"VBN,IN,DT\", \"DT,NN,NN\", \"IN,PRP$,NN\", \"NNP,VBD,VBN\", \"NNP,CC,NNP\", \"NNS,IN,DT\", \"NN,IN,NN\", \"DT,NN,VBD\", \"NN,VBD,VBN\", \"TO,VB,DT\", \"NNP,POS,NN\", \"ter\", \"er_\", \"_wa\", \"was\", \"as_\", \"s_a\", \"_a_\", \"an_\", \"e_a\", \"_an\", \"and\", \"nd_\", \"_re\", \"ent\", \"_of\", \"of_\", \"f_t\", \"_th\", \"the\", \"he_\", \"on_\", \",_a\", \"at_\", \"ed_\", \"_on\", \"n_t\", \"or_\", \"ing\", \"ng_\", \"_in\", \"in_\", \"d_t\", \"d_a\", \"_he\", \"_to\", \"ted\", \"th_\", \"al_\", \"es_\", \"ate\", \"_co\", \"ion\", \"ere\", \"_fo\", \"for\", \"s,_\", \"to_\", \"ati\", \"st_\", \"re_\", \"_be\", \"ly_\", \"her\", \"_hi\", \"his\", \"is_\", \"e_t\", \"en_\", \"e_o\", \"t_t\", \"tio\", \"_Th\" ]\n",
    "\n",
    "# Select only the columns corresponding to the features in the list\n",
    "X = data[features_cols]\n",
    "\n",
    "X.sample(frac=1)\n",
    "\n",
    "# Select qualityClass as the response (y)\n",
    "y = data.qualityClass\n",
    "\n",
    "# Select only the columns corresponding to the features in the list\n",
    "X = data[features_cols]\n",
    "\n",
    "X.sample(frac=1)\n",
    "\n",
    "# Select qualityClass as the response (y)\n",
    "y = data.qualityClass\n",
    "\n",
    "print('\\n')\n",
    "print('Decision Tree')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with decision tree PREDICTIONS\n",
    "clf = DecisionTreeClassifier(random_state=8)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('KNN')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with knn PREDICTIONS\n",
    "clf = KNeighborsClassifier(n_jobs=7, n_neighbors=49) # NORMAL\n",
    "# clf = KNeighborsClassifier(n_jobs=7, n_neighbors=25) # PARALLEL\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Logistic Regression')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with logistic regression PREDICTIONS\n",
    "clf = LogisticRegression(n_jobs=7)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Naive Bayes')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with naive bayes PREDICTIONS\n",
    "clf = GaussianNB()\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Random Forest')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with random forst PREDICTIONS\n",
    "clf = RandomForestClassifier(n_jobs=7, n_estimators=200, random_state=5, class_weight='auto')\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Support Vector Classifier')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with support vector classifier PREDICTIONS\n",
    "clf = LinearSVC(dual=False)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "print('\\n')\n",
    "print('XGBoost')\n",
    "print('\\n')\n",
    "# fit model no training data\n",
    "model = XGBClassifier(max_depth=3, n_estimators=1000, n_jobs=7)\n",
    "\n",
    "# 10-fold cross-validation with decision tree PREDICTIONS\n",
    "y_pred = cross_val_predict(model, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred) ))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My approach - Network Features Only\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.58      0.60       400\n",
      "          2       0.28      0.29      0.28       400\n",
      "          3       0.22      0.24      0.23       400\n",
      "          4       0.24      0.24      0.24       400\n",
      "          5       0.31      0.29      0.30       400\n",
      "          6       0.37      0.38      0.37       400\n",
      "          7       0.44      0.42      0.43       400\n",
      "\n",
      "avg / total       0.35      0.35      0.35      2800\n",
      "\n",
      "Accuracy: 0.3482142857142857\n",
      "MSE: 2.7385714285714284\n",
      "\n",
      "\n",
      "KNN\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.45      0.69      0.55       400\n",
      "          2       0.26      0.24      0.25       400\n",
      "          3       0.19      0.07      0.10       400\n",
      "          4       0.12      0.06      0.08       400\n",
      "          5       0.21      0.20      0.20       400\n",
      "          6       0.28      0.34      0.31       400\n",
      "          7       0.37      0.55      0.44       400\n",
      "\n",
      "avg / total       0.27      0.31      0.28      2800\n",
      "\n",
      "Accuracy: 0.3067857142857143\n",
      "MSE: 4.070357142857143\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.82      0.65       400\n",
      "          2       0.33      0.34      0.34       400\n",
      "          3       0.41      0.22      0.28       400\n",
      "          4       0.26      0.18      0.21       400\n",
      "          5       0.37      0.29      0.33       400\n",
      "          6       0.41      0.42      0.41       400\n",
      "          7       0.47      0.66      0.55       400\n",
      "\n",
      "avg / total       0.40      0.42      0.40      2800\n",
      "\n",
      "Accuracy: 0.41892857142857143\n",
      "MSE: 2.5010714285714286\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.28      0.93      0.44       400\n",
      "          2       0.13      0.26      0.17       400\n",
      "          3       0.35      0.07      0.12       400\n",
      "          4       0.25      0.01      0.01       400\n",
      "          5       0.33      0.00      0.00       400\n",
      "          6       0.29      0.27      0.28       400\n",
      "          7       0.38      0.21      0.27       400\n",
      "\n",
      "avg / total       0.29      0.25      0.19      2800\n",
      "\n",
      "Accuracy: 0.25\n",
      "MSE: 6.785357142857142\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.76      0.71       400\n",
      "          2       0.35      0.31      0.33       400\n",
      "          3       0.37      0.30      0.33       400\n",
      "          4       0.35      0.28      0.31       400\n",
      "          5       0.43      0.39      0.41       400\n",
      "          6       0.41      0.44      0.42       400\n",
      "          7       0.52      0.69      0.59       400\n",
      "\n",
      "avg / total       0.44      0.45      0.44      2800\n",
      "\n",
      "Accuracy: 0.45285714285714285\n",
      "MSE: 1.8717857142857144\n",
      "\n",
      "\n",
      "Support Vector Classifier\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.87      0.62       400\n",
      "          2       0.29      0.30      0.29       400\n",
      "          3       0.37      0.12      0.18       400\n",
      "          4       0.26      0.13      0.17       400\n",
      "          5       0.39      0.25      0.30       400\n",
      "          6       0.40      0.41      0.40       400\n",
      "          7       0.45      0.72      0.55       400\n",
      "\n",
      "avg / total       0.38      0.40      0.36      2800\n",
      "\n",
      "Accuracy: 0.4007142857142857\n",
      "MSE: 2.8914285714285715\n",
      "\n",
      "\n",
      "XGBoost\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       400\n",
      "          2       0.36      0.34      0.35       400\n",
      "          3       0.37      0.33      0.35       400\n",
      "          4       0.35      0.32      0.33       400\n",
      "          5       0.43      0.42      0.43       400\n",
      "          6       0.44      0.47      0.45       400\n",
      "          7       0.54      0.64      0.59       400\n",
      "\n",
      "avg / total       0.46      0.46      0.46      2800\n",
      "\n",
      "Accuracy: 0.46285714285714286\n",
      "MSE: 1.8064285714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "import csv\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "# Import classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Change it with the name of your dataset\n",
    "filename = 'MHDataset.csv'\n",
    "\n",
    "# Extract columns names (fieldnames)\n",
    "with open(filename, 'r') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = reader.fieldnames\n",
    "\n",
    "# Remove last column (qualityClass)\n",
    "fieldnames.pop()\n",
    "\n",
    "# IMPORT DATASET\n",
    "data = pd.read_csv(open(filename))\n",
    "\n",
    "# My approach\n",
    "print('My approach - Network & Review Features')\n",
    "\n",
    "# Feature list\n",
    "features_cols = [\"pageRank\", \"indegree\", \"outdegree\", \"assortativity_inin\", \"assortativity_inout\", \"assortativity_outin\", \"assortativity_outout\", \"localClusteringCoefficient\", \"reciprocity\", \"linkCount\", \"translationCount\", \"age\", \"agePerReview\", \"reviewPerDay\", \"reviewsPerUser\", \"reviewsPerUserStdDev\", \"discussionCount\", \"reviewCount\", \"registeredReviewCount\", \"anonymouseReviewCount\", \"registeredReviewRate\", \"anonymouseReviewRate\", \"registeredAnonymouseReviewRatio\", \"userCount\", \"occasionalUserCount\", \"occasionalUserRate\", \"registeredUserCount\", \"anonymouseUserCount\", \"registerdAnonymouseUserRatio\", \"registeredUserRate\", \"anonymouseUserRate\", \"revertCount\", \"revertReviewRatio\", \"diversity\", \"modifiedLinesRate\", \"mostActiveUsersReviewCount\", \"mostActiveUsersReviewRate\", \"occasionalUsersReviewCount\", \"occasionalUsersReviewRate\", \"lastThreeMonthsReviewCount\", \"lastThreeMonthsReviewRate\" ]\n",
    "\n",
    "# Select only the columns corresponding to the features in the list\n",
    "X = data[features_cols]\n",
    "\n",
    "X.sample(frac=1)\n",
    "\n",
    "# Select qualityClass as the response (y)\n",
    "y = data.qualityClass\n",
    "\n",
    "# Select only the columns corresponding to the features in the list\n",
    "X = data[features_cols]\n",
    "\n",
    "X.sample(frac=1)\n",
    "\n",
    "# Select qualityClass as the response (y)\n",
    "y = data.qualityClass\n",
    "\n",
    "print('\\n')\n",
    "print('Decision Tree')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with decision tree PREDICTIONS\n",
    "clf = DecisionTreeClassifier(random_state=8)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('KNN')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with knn PREDICTIONS\n",
    "clf = KNeighborsClassifier(n_jobs=7, n_neighbors=49) # NORMAL\n",
    "# clf = KNeighborsClassifier(n_jobs=7, n_neighbors=25) # PARALLEL\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Logistic Regression')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with logistic regression PREDICTIONS\n",
    "clf = LogisticRegression(n_jobs=7)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Naive Bayes')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with naive bayes PREDICTIONS\n",
    "clf = GaussianNB()\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Random Forest')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with random forst PREDICTIONS\n",
    "clf = RandomForestClassifier(n_jobs=7, n_estimators=200, random_state=5, class_weight='auto')\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Support Vector Classifier')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with support vector classifier PREDICTIONS\n",
    "clf = LinearSVC(dual=False)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "print('\\n')\n",
    "print('XGBoost')\n",
    "print('\\n')\n",
    "# fit model no training data\n",
    "model = XGBClassifier(max_depth=3, n_estimators=1000, n_jobs=7)\n",
    "\n",
    "# 10-fold cross-validation with decision tree PREDICTIONS\n",
    "y_pred = cross_val_predict(model, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred) ))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My approach - Network & Text Features\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63       400\n",
      "          2       0.34      0.35      0.34       400\n",
      "          3       0.29      0.28      0.28       400\n",
      "          4       0.28      0.29      0.29       400\n",
      "          5       0.40      0.40      0.40       400\n",
      "          6       0.35      0.35      0.35       400\n",
      "          7       0.43      0.43      0.43       400\n",
      "\n",
      "avg / total       0.39      0.39      0.39      2800\n",
      "\n",
      "Accuracy: 0.3892857142857143\n",
      "MSE: 1.9242857142857144\n",
      "\n",
      "\n",
      "KNN\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.81      0.73       400\n",
      "          2       0.39      0.35      0.37       400\n",
      "          3       0.18      0.07      0.10       400\n",
      "          4       0.31      0.23      0.26       400\n",
      "          5       0.39      0.42      0.41       400\n",
      "          6       0.34      0.34      0.34       400\n",
      "          7       0.39      0.67      0.49       400\n",
      "\n",
      "avg / total       0.38      0.41      0.39      2800\n",
      "\n",
      "Accuracy: 0.4125\n",
      "MSE: 2.1332142857142857\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.80      0.72       400\n",
      "          2       0.40      0.44      0.42       400\n",
      "          3       0.36      0.28      0.32       400\n",
      "          4       0.40      0.38      0.39       400\n",
      "          5       0.44      0.44      0.44       400\n",
      "          6       0.46      0.43      0.44       400\n",
      "          7       0.54      0.55      0.55       400\n",
      "\n",
      "avg / total       0.47      0.47      0.47      2800\n",
      "\n",
      "Accuracy: 0.475\n",
      "MSE: 1.4925\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.95      0.65       400\n",
      "          2       0.18      0.35      0.24       400\n",
      "          3       0.16      0.17      0.16       400\n",
      "          4       0.75      0.01      0.01       400\n",
      "          5       0.15      0.09      0.11       400\n",
      "          6       0.35      0.23      0.28       400\n",
      "          7       0.43      0.34      0.38       400\n",
      "\n",
      "avg / total       0.36      0.30      0.26      2800\n",
      "\n",
      "Accuracy: 0.30392857142857144\n",
      "MSE: 3.5396428571428573\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.80      0.76       400\n",
      "          2       0.46      0.48      0.47       400\n",
      "          3       0.46      0.31      0.37       400\n",
      "          4       0.43      0.36      0.39       400\n",
      "          5       0.54      0.47      0.50       400\n",
      "          6       0.45      0.54      0.49       400\n",
      "          7       0.51      0.65      0.57       400\n",
      "\n",
      "avg / total       0.51      0.51      0.51      2800\n",
      "\n",
      "Accuracy: 0.5146428571428572\n",
      "MSE: 1.3307142857142857\n",
      "\n",
      "\n",
      "Support Vector Classifier\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.84      0.73       400\n",
      "          2       0.40      0.43      0.42       400\n",
      "          3       0.38      0.28      0.32       400\n",
      "          4       0.39      0.35      0.37       400\n",
      "          5       0.42      0.42      0.42       400\n",
      "          6       0.44      0.43      0.44       400\n",
      "          7       0.53      0.55      0.54       400\n",
      "\n",
      "avg / total       0.46      0.47      0.46      2800\n",
      "\n",
      "Accuracy: 0.4717857142857143\n",
      "MSE: 1.5014285714285713\n",
      "\n",
      "\n",
      "XGBoost\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       400\n",
      "          2       0.48      0.46      0.47       400\n",
      "          3       0.48      0.39      0.43       400\n",
      "          4       0.47      0.46      0.46       400\n",
      "          5       0.52      0.48      0.50       400\n",
      "          6       0.47      0.52      0.50       400\n",
      "          7       0.58      0.65      0.62       400\n",
      "\n",
      "avg / total       0.53      0.53      0.53      2800\n",
      "\n",
      "Accuracy: 0.5342857142857143\n",
      "MSE: 1.0871428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "import csv\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "# Import classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Change it with the name of your dataset\n",
    "filename = 'MHDataset.csv'\n",
    "\n",
    "# Extract columns names (fieldnames)\n",
    "with open(filename, 'r') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = reader.fieldnames\n",
    "\n",
    "# Remove last column (qualityClass)\n",
    "fieldnames.pop()\n",
    "\n",
    "# IMPORT DATASET\n",
    "data = pd.read_csv(open(filename))\n",
    "\n",
    "# My approach\n",
    "print('My approach - Network & Text Features')\n",
    "\n",
    "# Feature list\n",
    "features_cols = [\"pageRank\", \"indegree\", \"outdegree\", \"assortativity_inin\", \"assortativity_inout\", \"assortativity_outin\", \"assortativity_outout\", \"localClusteringCoefficient\", \"reciprocity\", \"linkCount\", \"translationCount\", \"characterCount\", \"wordCount\", \"syllableCount\", \"sentenceCount\", \"sectionCount\", \"subsectionCount\", \"paragraphCount\", \"meanSectionSize\", \"meanParagraphSize\", \"largestSectionSize\", \"shortestSectionSize\", \"largestShortestSectionRatio\", \"sectionSizeStandardDeviation\", \"meanOfSubsectionsPerSection\", \"abstractSize\", \"abstractSizeArtcileLengthRatio\", \"citationCount\", \"citationCountPerTextLength\", \"citationCountPerSection\", \"externalLinksCount\", \"externalLinksPerTextLength\", \"externalLinksPerSection\", \"imageCount\", \"imagePerTextLength\", \"imagePerSection\", \"meanSentenceSize\", \"largestSentenceSize\", \"shortestSentenceSize\", \"largeSentenceRate\", \"shortSentenceRate\", \"questionCount\", \"questionRatio\", \"exclamationCount\", \"exclamationRatio\", \"toBeVerbCount\", \"toBeVerbRatio\", \"toBeVerbPerSentence\", \"toBeVerbRate\", \"modalAuxiliaryVerbCount\", \"modalAuxiliaryVerbsRatio\", \"modalAuxiliaryVerbsPerSentence\", \"modalAuxiliaryVerbsRate\", \"passiveVoiceCount\", \"passiveVoiceRatio\", \"passiveVoicePerSentence\", \"passiveVoiceRate\", \"numberOfSentencesThatStartWithACoordinatingConjunction\", \"numberOfSentencesThatStartWithADeterminer\", \"numberOfSentencesThatStartWithASubordinatingPrepositionOrConjunction\", \"numberOfSentencesThatStartWithAnAdjective\", \"numberOfSentencesThatStartWithANoun\", \"numberOfSentencesThatStartWithAPronoun\", \"numberOfSentencesThatStartWithAnAdverb\", \"numberOfSentencesThatStartWithAnArticle\", \"numberOfSentencesThatStartWithACoordinatingConjunctionRatio\", \"numberOfSentencesThatStartWithADeterminerRatio\", \"numberOfSentencesThatStartWithASubordinatingPrepositionOrConjunctionRatio\", \"numberOfSentencesThatStartWithAnAdjectiveRatio\", \"numberOfSentencesThatStartWithANounRatio\", \"numberOfSentencesThatStartWithAPronounRatio\", \"numberOfSentencesThatStartWithAnAdverbRatio\", \"numberOfSentencesThatStartWithAnArticleRatio\", \"automatedReadabilityIndex\", \"colemanLiauIndex\", \"fleshReadingEase\", \"fleschKincaidGradeLevel\", \"gunningFogIndex\", \"lasbarhetsIndex\", \"smogGrading\", \"daleChallReadabilityFormula\", \"differentWordCount\", \"differentWordsPerSentence\", \"differentWordsRate\", \"nounCount\", \"nounsPerSentence\", \"nounsRate\", \"differentNounCount\", \"differentNounsPerSentence\", \"differentNounsRate\", \"differentNounsDifferentWordsRatio\", \"verbCount\", \"verbsPerSentence\", \"verbsRate\", \"differentVerbCount\", \"differentVerbsPerSentence\", \"differentVerbsRate\", \"differentVerbsDifferentWordsRatio\", \"pronounCount\", \"pronounsPerSentence\", \"pronounsRate\", \"differentPronounCount\", \"differentPronounsPerSentence\", \"differentPronounsRate\", \"differentPronounsDifferentWordsRatio\", \"adjectiveCount\", \"adjectivesPerSentence\", \"adjectivesRate\", \"differentAdjectiveCount\", \"differentAdjectivesPerSentence\", \"differentAdjectivesRate\", \"differentAdjectivesDifferentWordsRatio\", \"adverbCount\", \"adverbsPerSentence\", \"adverbsRate\", \"differentAdverbCount\", \"differentAdverbsPerSentence\", \"differentAdverbsRate\", \"differentAdverbsDifferentWordsRatio\", \"coordinatingConjunctionCount\", \"coordinatingConjunctionsPerSentence\", \"coordinatingConjunctionsRate\", \"differentCoordinatingConjunctionCount\", \"differentCoordinatingConjunctionsPerSentence\", \"differentCoordinatingConjunctionsRate\", \"differentCoordinatingConjunctionsDifferentWordsRatio\", \"subordinatingPrepositionAndConjunctionCount\", \"subordinatingPrepositionsAndConjunctionsPerSentence\", \"subordinatingPrepositionsAndConjunctionsRate\", \"differentSubordinatingPrepositionAndConjunctionCount\", \"differentSubordinatingPrepositionsAndConjunctionsPerSentence\", \"differentSubordinatingPrepositionsAndConjunctionsRate\", \"differentSubordinatingPrepositionsAndConjunctionsDifferentWordsRatio\", \"syllablesPerWord\", \"charactersPerWord\", \"NNP,NNP,NNP\", \"VBD,DT,JJ\", \"IN,DT,NNP\", \"NNP,IN,DT\", \"DT,NNP,NNP\", \"JJ,NN,IN\", \"NN,IN,DT\", \"IN,DT,NN\", \"NN,IN,NNP\", \"IN,NNP,NNP\", \"NNP,VBD,DT\", \"VBD,DT,NN\", \"DT,NN,IN\", \"VBD,VBN,IN\", \"NNP,NNP,VBD\", \"IN,NN,IN\", \"NNP,NNP,IN\", \"NNP,IN,NNP\", \"VBD,IN,DT\", \"IN,DT,JJ\", \"JJ,NNS,IN\", \"DT,JJ,NN\", \"IN,DT,NNS\", \"IN,CD,NNP\", \"VBN,IN,DT\", \"DT,NN,NN\", \"IN,PRP$,NN\", \"NNP,VBD,VBN\", \"NNP,CC,NNP\", \"NNS,IN,DT\", \"NN,IN,NN\", \"DT,NN,VBD\", \"NN,VBD,VBN\", \"TO,VB,DT\", \"NNP,POS,NN\", \"ter\", \"er_\", \"_wa\", \"was\", \"as_\", \"s_a\", \"_a_\", \"an_\", \"e_a\", \"_an\", \"and\", \"nd_\", \"_re\", \"ent\", \"_of\", \"of_\", \"f_t\", \"_th\", \"the\", \"he_\", \"on_\", \",_a\", \"at_\", \"ed_\", \"_on\", \"n_t\", \"or_\", \"ing\", \"ng_\", \"_in\", \"in_\", \"d_t\", \"d_a\", \"_he\", \"_to\", \"ted\", \"th_\", \"al_\", \"es_\", \"ate\", \"_co\", \"ion\", \"ere\", \"_fo\", \"for\", \"s,_\", \"to_\", \"ati\", \"st_\", \"re_\", \"_be\", \"ly_\", \"her\", \"_hi\", \"his\", \"is_\", \"e_t\", \"en_\", \"e_o\", \"t_t\", \"tio\", \"_Th\" ]\n",
    "\n",
    "# Select only the columns corresponding to the features in the list\n",
    "X = data[features_cols]\n",
    "\n",
    "X.sample(frac=1)\n",
    "\n",
    "# Select qualityClass as the response (y)\n",
    "y = data.qualityClass\n",
    "\n",
    "# Select only the columns corresponding to the features in the list\n",
    "X = data[features_cols]\n",
    "\n",
    "X.sample(frac=1)\n",
    "\n",
    "# Select qualityClass as the response (y)\n",
    "y = data.qualityClass\n",
    "\n",
    "print('\\n')\n",
    "print('Decision Tree')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with decision tree PREDICTIONS\n",
    "clf = DecisionTreeClassifier(random_state=8)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('KNN')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with knn PREDICTIONS\n",
    "clf = KNeighborsClassifier(n_jobs=7, n_neighbors=49) # NORMAL\n",
    "# clf = KNeighborsClassifier(n_jobs=7, n_neighbors=25) # PARALLEL\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Logistic Regression')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with logistic regression PREDICTIONS\n",
    "clf = LogisticRegression(n_jobs=7)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Naive Bayes')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with naive bayes PREDICTIONS\n",
    "clf = GaussianNB()\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Random Forest')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with random forst PREDICTIONS\n",
    "clf = RandomForestClassifier(n_jobs=7, n_estimators=200, random_state=5, class_weight='auto')\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Support Vector Classifier')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with support vector classifier PREDICTIONS\n",
    "clf = LinearSVC(dual=False)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "print('\\n')\n",
    "print('XGBoost')\n",
    "print('\\n')\n",
    "# fit model no training data\n",
    "model = XGBClassifier(max_depth=3, n_estimators=1000, n_jobs=7)\n",
    "\n",
    "# 10-fold cross-validation with decision tree PREDICTIONS\n",
    "y_pred = cross_val_predict(model, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred) ))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My approach - Review & Text Features\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63       400\n",
      "          2       0.32      0.31      0.32       400\n",
      "          3       0.27      0.27      0.27       400\n",
      "          4       0.28      0.28      0.28       400\n",
      "          5       0.39      0.40      0.39       400\n",
      "          6       0.35      0.37      0.36       400\n",
      "          7       0.44      0.42      0.43       400\n",
      "\n",
      "avg / total       0.38      0.38      0.38      2800\n",
      "\n",
      "Accuracy: 0.38285714285714284\n",
      "MSE: 2.035357142857143\n",
      "\n",
      "\n",
      "KNN\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.84      0.74       400\n",
      "          2       0.43      0.35      0.38       400\n",
      "          3       0.22      0.07      0.11       400\n",
      "          4       0.33      0.23      0.27       400\n",
      "          5       0.36      0.39      0.37       400\n",
      "          6       0.34      0.39      0.37       400\n",
      "          7       0.40      0.66      0.50       400\n",
      "\n",
      "avg / total       0.39      0.42      0.39      2800\n",
      "\n",
      "Accuracy: 0.41964285714285715\n",
      "MSE: 2.157857142857143\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.81      0.73       400\n",
      "          2       0.41      0.43      0.42       400\n",
      "          3       0.36      0.31      0.33       400\n",
      "          4       0.39      0.36      0.37       400\n",
      "          5       0.46      0.46      0.46       400\n",
      "          6       0.47      0.46      0.47       400\n",
      "          7       0.58      0.59      0.58       400\n",
      "\n",
      "avg / total       0.48      0.49      0.48      2800\n",
      "\n",
      "Accuracy: 0.4875\n",
      "MSE: 1.375\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.95      0.64       400\n",
      "          2       0.16      0.33      0.22       400\n",
      "          3       0.17      0.15      0.16       400\n",
      "          4       0.50      0.00      0.00       400\n",
      "          5       0.17      0.10      0.12       400\n",
      "          6       0.33      0.24      0.28       400\n",
      "          7       0.44      0.34      0.39       400\n",
      "\n",
      "avg / total       0.32      0.30      0.26      2800\n",
      "\n",
      "Accuracy: 0.30214285714285716\n",
      "MSE: 3.5260714285714285\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.80      0.75       400\n",
      "          2       0.47      0.47      0.47       400\n",
      "          3       0.41      0.30      0.35       400\n",
      "          4       0.48      0.36      0.41       400\n",
      "          5       0.55      0.49      0.52       400\n",
      "          6       0.49      0.55      0.52       400\n",
      "          7       0.54      0.72      0.61       400\n",
      "\n",
      "avg / total       0.52      0.53      0.52      2800\n",
      "\n",
      "Accuracy: 0.5267857142857143\n",
      "MSE: 1.2589285714285714\n",
      "\n",
      "\n",
      "Support Vector Classifier\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.84      0.72       400\n",
      "          2       0.40      0.41      0.40       400\n",
      "          3       0.37      0.28      0.32       400\n",
      "          4       0.41      0.35      0.38       400\n",
      "          5       0.47      0.48      0.47       400\n",
      "          6       0.47      0.45      0.46       400\n",
      "          7       0.58      0.61      0.60       400\n",
      "\n",
      "avg / total       0.48      0.49      0.48      2800\n",
      "\n",
      "Accuracy: 0.48857142857142855\n",
      "MSE: 1.4289285714285713\n",
      "\n",
      "\n",
      "XGBoost\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.77      0.75       400\n",
      "          2       0.46      0.45      0.46       400\n",
      "          3       0.41      0.36      0.39       400\n",
      "          4       0.42      0.41      0.41       400\n",
      "          5       0.54      0.47      0.50       400\n",
      "          6       0.50      0.55      0.52       400\n",
      "          7       0.63      0.72      0.67       400\n",
      "\n",
      "avg / total       0.53      0.53      0.53      2800\n",
      "\n",
      "Accuracy: 0.5335714285714286\n",
      "MSE: 1.0367857142857142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:166: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "import csv\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Change it with the name of your dataset\n",
    "filename = 'MHDataset.csv'\n",
    "\n",
    "# Extract columns names (fieldnames)\n",
    "with open(filename, 'r') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = reader.fieldnames\n",
    "\n",
    "# Remove last column (qualityClass)\n",
    "fieldnames.pop()\n",
    "\n",
    "# IMPORT DATASET\n",
    "data = pd.read_csv(open(filename))\n",
    "\n",
    "# My approach\n",
    "print('My approach - Review & Text Features')\n",
    "\n",
    "# Feature list\n",
    "features_cols = [ \"age\", \"agePerReview\", \"reviewPerDay\", \"reviewsPerUser\", \"reviewsPerUserStdDev\", \"discussionCount\", \"reviewCount\", \"registeredReviewCount\", \"anonymouseReviewCount\", \"registeredReviewRate\", \"anonymouseReviewRate\", \"registeredAnonymouseReviewRatio\", \"userCount\", \"occasionalUserCount\", \"occasionalUserRate\", \"registeredUserCount\", \"anonymouseUserCount\", \"registerdAnonymouseUserRatio\", \"registeredUserRate\", \"anonymouseUserRate\", \"revertCount\", \"revertReviewRatio\", \"diversity\", \"modifiedLinesRate\", \"mostActiveUsersReviewCount\", \"mostActiveUsersReviewRate\", \"occasionalUsersReviewCount\", \"occasionalUsersReviewRate\", \"lastThreeMonthsReviewCount\", \"lastThreeMonthsReviewRate\", \"characterCount\", \"wordCount\", \"syllableCount\", \"sentenceCount\", \"sectionCount\", \"subsectionCount\", \"paragraphCount\", \"meanSectionSize\", \"meanParagraphSize\", \"largestSectionSize\", \"shortestSectionSize\", \"largestShortestSectionRatio\", \"sectionSizeStandardDeviation\", \"meanOfSubsectionsPerSection\", \"abstractSize\", \"abstractSizeArtcileLengthRatio\", \"citationCount\", \"citationCountPerTextLength\", \"citationCountPerSection\", \"externalLinksCount\", \"externalLinksPerTextLength\", \"externalLinksPerSection\", \"imageCount\", \"imagePerTextLength\", \"imagePerSection\", \"meanSentenceSize\", \"largestSentenceSize\", \"shortestSentenceSize\", \"largeSentenceRate\", \"shortSentenceRate\", \"questionCount\", \"questionRatio\", \"exclamationCount\", \"exclamationRatio\", \"toBeVerbCount\", \"toBeVerbRatio\", \"toBeVerbPerSentence\", \"toBeVerbRate\", \"modalAuxiliaryVerbCount\", \"modalAuxiliaryVerbsRatio\", \"modalAuxiliaryVerbsPerSentence\", \"modalAuxiliaryVerbsRate\", \"passiveVoiceCount\", \"passiveVoiceRatio\", \"passiveVoicePerSentence\", \"passiveVoiceRate\", \"numberOfSentencesThatStartWithACoordinatingConjunction\", \"numberOfSentencesThatStartWithADeterminer\", \"numberOfSentencesThatStartWithASubordinatingPrepositionOrConjunction\", \"numberOfSentencesThatStartWithAnAdjective\", \"numberOfSentencesThatStartWithANoun\", \"numberOfSentencesThatStartWithAPronoun\", \"numberOfSentencesThatStartWithAnAdverb\", \"numberOfSentencesThatStartWithAnArticle\", \"numberOfSentencesThatStartWithACoordinatingConjunctionRatio\", \"numberOfSentencesThatStartWithADeterminerRatio\", \"numberOfSentencesThatStartWithASubordinatingPrepositionOrConjunctionRatio\", \"numberOfSentencesThatStartWithAnAdjectiveRatio\", \"numberOfSentencesThatStartWithANounRatio\", \"numberOfSentencesThatStartWithAPronounRatio\", \"numberOfSentencesThatStartWithAnAdverbRatio\", \"numberOfSentencesThatStartWithAnArticleRatio\", \"automatedReadabilityIndex\", \"colemanLiauIndex\", \"fleshReadingEase\", \"fleschKincaidGradeLevel\", \"gunningFogIndex\", \"lasbarhetsIndex\", \"smogGrading\", \"daleChallReadabilityFormula\", \"differentWordCount\", \"differentWordsPerSentence\", \"differentWordsRate\", \"nounCount\", \"nounsPerSentence\", \"nounsRate\", \"differentNounCount\", \"differentNounsPerSentence\", \"differentNounsRate\", \"differentNounsDifferentWordsRatio\", \"verbCount\", \"verbsPerSentence\", \"verbsRate\", \"differentVerbCount\", \"differentVerbsPerSentence\", \"differentVerbsRate\", \"differentVerbsDifferentWordsRatio\", \"pronounCount\", \"pronounsPerSentence\", \"pronounsRate\", \"differentPronounCount\", \"differentPronounsPerSentence\", \"differentPronounsRate\", \"differentPronounsDifferentWordsRatio\", \"adjectiveCount\", \"adjectivesPerSentence\", \"adjectivesRate\", \"differentAdjectiveCount\", \"differentAdjectivesPerSentence\", \"differentAdjectivesRate\", \"differentAdjectivesDifferentWordsRatio\", \"adverbCount\", \"adverbsPerSentence\", \"adverbsRate\", \"differentAdverbCount\", \"differentAdverbsPerSentence\", \"differentAdverbsRate\", \"differentAdverbsDifferentWordsRatio\", \"coordinatingConjunctionCount\", \"coordinatingConjunctionsPerSentence\", \"coordinatingConjunctionsRate\", \"differentCoordinatingConjunctionCount\", \"differentCoordinatingConjunctionsPerSentence\", \"differentCoordinatingConjunctionsRate\", \"differentCoordinatingConjunctionsDifferentWordsRatio\", \"subordinatingPrepositionAndConjunctionCount\", \"subordinatingPrepositionsAndConjunctionsPerSentence\", \"subordinatingPrepositionsAndConjunctionsRate\", \"differentSubordinatingPrepositionAndConjunctionCount\", \"differentSubordinatingPrepositionsAndConjunctionsPerSentence\", \"differentSubordinatingPrepositionsAndConjunctionsRate\", \"differentSubordinatingPrepositionsAndConjunctionsDifferentWordsRatio\", \"syllablesPerWord\", \"charactersPerWord\", \"NNP,NNP,NNP\", \"VBD,DT,JJ\", \"IN,DT,NNP\", \"NNP,IN,DT\", \"DT,NNP,NNP\", \"JJ,NN,IN\", \"NN,IN,DT\", \"IN,DT,NN\", \"NN,IN,NNP\", \"IN,NNP,NNP\", \"NNP,VBD,DT\", \"VBD,DT,NN\", \"DT,NN,IN\", \"VBD,VBN,IN\", \"NNP,NNP,VBD\", \"IN,NN,IN\", \"NNP,NNP,IN\", \"NNP,IN,NNP\", \"VBD,IN,DT\", \"IN,DT,JJ\", \"JJ,NNS,IN\", \"DT,JJ,NN\", \"IN,DT,NNS\", \"IN,CD,NNP\", \"VBN,IN,DT\", \"DT,NN,NN\", \"IN,PRP$,NN\", \"NNP,VBD,VBN\", \"NNP,CC,NNP\", \"NNS,IN,DT\", \"NN,IN,NN\", \"DT,NN,VBD\", \"NN,VBD,VBN\", \"TO,VB,DT\", \"NNP,POS,NN\", \"ter\", \"er_\", \"_wa\", \"was\", \"as_\", \"s_a\", \"_a_\", \"an_\", \"e_a\", \"_an\", \"and\", \"nd_\", \"_re\", \"ent\", \"_of\", \"of_\", \"f_t\", \"_th\", \"the\", \"he_\", \"on_\", \",_a\", \"at_\", \"ed_\", \"_on\", \"n_t\", \"or_\", \"ing\", \"ng_\", \"_in\", \"in_\", \"d_t\", \"d_a\", \"_he\", \"_to\", \"ted\", \"th_\", \"al_\", \"es_\", \"ate\", \"_co\", \"ion\", \"ere\", \"_fo\", \"for\", \"s,_\", \"to_\", \"ati\", \"st_\", \"re_\", \"_be\", \"ly_\", \"her\", \"_hi\", \"his\", \"is_\", \"e_t\", \"en_\", \"e_o\", \"t_t\", \"tio\", \"_Th\" ]\n",
    "\n",
    "# Select only the columns corresponding to the features in the list\n",
    "X = data[features_cols]\n",
    "\n",
    "X.sample(frac=1)\n",
    "\n",
    "# Select qualityClass as the response (y)\n",
    "y = data.qualityClass\n",
    "\n",
    "# Select only the columns corresponding to the features in the list\n",
    "X = data[features_cols]\n",
    "\n",
    "X.sample(frac=1)\n",
    "\n",
    "# Select qualityClass as the response (y)\n",
    "y = data.qualityClass\n",
    "\n",
    "print('\\n')\n",
    "print('Decision Tree')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with decision tree PREDICTIONS\n",
    "clf = DecisionTreeClassifier(random_state=8)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('KNN')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with knn PREDICTIONS\n",
    "clf = KNeighborsClassifier(n_jobs=7, n_neighbors=49) # NORMAL\n",
    "# clf = KNeighborsClassifier(n_jobs=7, n_neighbors=25) # PARALLEL\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Logistic Regression')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with logistic regression PREDICTIONS\n",
    "clf = LogisticRegression(n_jobs=7)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Naive Bayes')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with naive bayes PREDICTIONS\n",
    "clf = GaussianNB()\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Random Forest')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with random forst PREDICTIONS\n",
    "clf = RandomForestClassifier(n_jobs=7, n_estimators=200, random_state=5, class_weight='auto')\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Support Vector Classifier')\n",
    "print('\\n')\n",
    "# 10-fold cross-validation with support vector classifier PREDICTIONS\n",
    "clf = LinearSVC(dual=False)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred)))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "print('\\n')\n",
    "print('XGBoost')\n",
    "print('\\n')\n",
    "# fit model no training data\n",
    "model = XGBClassifier(max_depth=3, n_estimators=1000, n_jobs=7)\n",
    "\n",
    "# 10-fold cross-validation with decision tree PREDICTIONS\n",
    "y_pred = cross_val_predict(model, X, y, cv=20)\n",
    "\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y, y_pred) ))\n",
    "print('MSE: ' + str(metrics.mean_squared_error(y, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
